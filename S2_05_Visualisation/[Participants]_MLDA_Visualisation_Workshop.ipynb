{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Participants] MLDA_Visualisation_Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HG21H-dZCo0R",
        "7PuZXsKdtUcd",
        "19NYXGAgr9-x"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qrsb4fxeojg"
      },
      "source": [
        "# Data Analytics (HX)\n",
        "\n",
        "We will be using a open source dataset of Pokemon Go Spawns at the San Francisco Bay Area, from [Kaggle](https://www.kaggle.com/datasets/kveykva/sf-bay-area-pokemon-go-spawns).\n",
        "\n",
        "Using this dataset, we will attempt to analyse for various data insights and obtain a comprehensive description of the data by investigating the distribution of pokemon by various factors (Name, Type, Time etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG21H-dZCo0R"
      },
      "source": [
        "## Extracting the dataset from Google Drive\n",
        "\n",
        "Run these cells to download the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjlLwkVLCsN2"
      },
      "outputs": [],
      "source": [
        "# Download the csv file from google drive into the sample_data folder\n",
        "! wget \"https://drive.google.com/u/0/uc?id=1NGvsf9pwkXW_3G6xM7ar-OhnviYNjFKJ&export=download\" -O \"pokemon-spawns.csv\" \n",
        "! mv pokemon-spawns.csv /content/sample_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PuZXsKdtUcd"
      },
      "source": [
        "## Data Pre-Processing\n",
        "1. Read the csv file we have using the Pandas library\n",
        "\n",
        "2. Display the dataframe obtained\n",
        "\n",
        "3. Optimise memory usage\n",
        "\n",
        "4. Filter unnecessary information, noisy data and perform miscellaneous data appending or slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQpqlFoMsfDC"
      },
      "outputs": [],
      "source": [
        "# Converting the csv file into a pandas dataframe\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "raw_df = pd.read_csv('sample_data/pokemon-spawns.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgFjhRgctoao"
      },
      "outputs": [],
      "source": [
        "# Sampling random indexes of the dataframe to see the kind of data we are dealing with\n",
        "print(raw_df.shape)\n",
        "raw_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3GuudZBz_lc"
      },
      "outputs": [],
      "source": [
        "# Retrieving all Pidgey spawns\n",
        "raw_df[raw_df[\"name\"] == \"Pidgey\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge5Ij3kwLe5j"
      },
      "outputs": [],
      "source": [
        "# Checking for weird data with invalid encounter_ms\n",
        "raw_df[raw_df[\"encounter_ms\"] <= 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8mx61cv1dH8"
      },
      "outputs": [],
      "source": [
        "# Column rename and checking for weird data with invalid disappear_ms\n",
        "raw_df.rename(columns={\"disppear_ms\":\"disappear_ms\"}, inplace=True)\n",
        "raw_df[raw_df[\"disappear_ms\"] <= 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEzJgHIIkq7q"
      },
      "outputs": [],
      "source": [
        "# Retrieving all Nidoran ♀ spawns\n",
        "raw_df[(raw_df['num'] == 29)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lprjvEUSlDRg"
      },
      "outputs": [],
      "source": [
        "# Retrieving all Nidoran ♂ spawns\n",
        "raw_df[(raw_df['num'] == 32)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56n0ei5Yfdem"
      },
      "source": [
        "Interesting Points to note:\n",
        "\n",
        "1. There exists datapoints with encounter_ms = -1, but there exists no datapoints with disappear_ms = -1.\n",
        "\n",
        "2. The timestamps of encounter_ms are later than timestamps of disappear_ms.\n",
        "\n",
        "3. 2 different name labels for Nidoran (eg. Nidoran♂ and Nidoran (m))\n",
        "\n",
        "4. There is a lack of information regarding pokemon types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9auQgRz2f70r"
      },
      "source": [
        "Assumptions / Conclusions:\n",
        "\n",
        "1. Datapoints with encounter_ms = -1 indicate pokemon that weren't encountered by Pokemon Trainers (ie. left to despawn)\n",
        "\n",
        "2. Mislabelled data? disappear_ms should be spawn_ms instead.\n",
        "\n",
        "3. Duplicate labels for Nidoran"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YW2lPe1QVe-"
      },
      "outputs": [],
      "source": [
        "# Ralabelling encounter_ms = -1\n",
        "raw_df['encounter_ms'].replace(-1, np.nan, inplace=True)\n",
        "raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-MPSfkygeEp"
      },
      "outputs": [],
      "source": [
        "# Relabelling to spawn_ms\n",
        "raw_df.rename(columns={\"disappear_ms\":\"spawn_ms\"}, inplace=True)\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0OnP2wAlmLJ"
      },
      "outputs": [],
      "source": [
        "# Fixing the Nidoran issue\n",
        "raw_df['name'].replace('Nidoran (f)','Nidoran♀', inplace=True)\n",
        "raw_df[(raw_df['num'] == 29)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpcNHrcIiUIy"
      },
      "outputs": [],
      "source": [
        "# A more foolproof way of fixing the Nidoran issue + Add Pokemon Types\n",
        "type_df = pd.read_csv(\"https://gist.githubusercontent.com/armgilles/194bcff35001e7eb53a2a8b441e8b2c6/raw/92200bc0a673d5ce2110aaad4544ed6c4010f687/pokemon.csv\")\n",
        "type_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFuavYD5o6kx"
      },
      "outputs": [],
      "source": [
        "# Filtering the type df to get the information that we need\n",
        "type_df = type_df.loc[type_df['Generation'] == 1, ['#','Name','Type 1','Type 2']].drop_duplicates(subset=['#'])\n",
        "type_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B5xNyFuigIU"
      },
      "outputs": [],
      "source": [
        "# Adding types to the dataframe, and rearranging the dataframe columns\n",
        "raw_df = raw_df.merge(type_df,how='left',left_on='num',right_on='#').drop(columns=['#','name'])\n",
        "cols = list(raw_df)\n",
        "cols = cols[:3] + cols[-3:] + cols[3:7]\n",
        "raw_df = raw_df[cols]\n",
        "raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ5Gi3BFqsNs"
      },
      "outputs": [],
      "source": [
        "# Lowercase Column Names for linguistic Consistency\n",
        "cols = list(raw_df)\n",
        "cols = [name.lower() for name in cols]\n",
        "raw_df.columns = cols\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWq9Vq2h06yV"
      },
      "outputs": [],
      "source": [
        "# Information about the datatype used for every column\n",
        "raw_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjvEMKHJyuUy"
      },
      "source": [
        "More information on S2 Cells:\n",
        "https://pokemongohub.net/post/article/comprehensive-guide-s2-cells-pokemon-go/amp/\n",
        "\n",
        "Pokemon Pokedex:\n",
        "https://www.pokemon.com/us/pokedex/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6u4qAC1xmXZ"
      },
      "outputs": [],
      "source": [
        "# Dropping information about S2 Cells\n",
        "raw_df.drop(columns = [\"s2_id\",\"s2_token\"], inplace=True)\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo8zQmXey9zA"
      },
      "outputs": [],
      "source": [
        "# Optimising data storage\n",
        "raw_df['num'] = raw_df['num'].astype('uint16')\n",
        "raw_df['name'] = raw_df['name'].astype('category')\n",
        "raw_df['type 1'] = raw_df['type 1'].astype('category')\n",
        "raw_df['type 2'] = raw_df['type 2'].astype('category')\n",
        "raw_df['lat'] = raw_df['lat'].astype('float32')\n",
        "raw_df['lng'] = raw_df['lng'].astype('float32')\n",
        "raw_df['encounter_ms'] = pd.to_datetime(raw_df['encounter_ms'], unit='ms')\n",
        "raw_df['spawn_ms'] = pd.to_datetime(raw_df['spawn_ms'], unit='ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybxMyN1eyReb"
      },
      "outputs": [],
      "source": [
        "raw_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN3-OzGrzr3z"
      },
      "outputs": [],
      "source": [
        "raw_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVmN2HhhUA-m"
      },
      "outputs": [],
      "source": [
        "raw_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhfGEHEV4hly"
      },
      "outputs": [],
      "source": [
        "df = raw_df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUqdcXjI5fIt"
      },
      "source": [
        "## Google Colab Data Tables\n",
        "\n",
        "Colab includes an extension that renders pandas dataframes into interactive displays that can be filtered, sorted, and explored dynamically.\n",
        "\n",
        "Here, we will be using this built in google colab feature to further filter and refine our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgWFI2BS5ga5"
      },
      "outputs": [],
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfyEdlDs5rR5"
      },
      "outputs": [],
      "source": [
        "# Taking another look at our processed dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7U5K0Vp8K9O"
      },
      "outputs": [],
      "source": [
        "# Filtering 20000 random indexes from our dataframe and analysing using Colab Tables\n",
        "df.sample(20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESvB64DW3Sj2"
      },
      "outputs": [],
      "source": [
        "# Challenge 1: Look for any anomalous data not found near the San Francisco region; determine the location of these anomalous points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDVPrEWsoR0a"
      },
      "outputs": [],
      "source": [
        "data_table.disable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5ozx1UD9y4B"
      },
      "source": [
        "## Seaborn & Matplotlib\n",
        "\n",
        "Seaborn and Matplotlib are 2 common libraries used to visualise dataframes in a graphical or chart format. \n",
        "\n",
        "Both libraries are sufficient for most use cases. \n",
        "\n",
        "Here, we will be deriving various useful from our data using visualisation, such as the most common & least common pokemon spawns at the San Francisco Bay Area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJQfejiyJdm7"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzuJU8B0N5nf"
      },
      "outputs": [],
      "source": [
        "# Taking another look at our processed dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb-6gzyr7Ljr"
      },
      "outputs": [],
      "source": [
        "# Count plot of all pokemon\n",
        "df.num.value_counts().plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4tw7GYAJupE"
      },
      "outputs": [],
      "source": [
        "# Count plot of the 10 most common pokemon\n",
        "df.name.value_counts().sort_values()[-10:].plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhr7N19XrnfA"
      },
      "outputs": [],
      "source": [
        "# Challenge 2: Count plot of the 10 least common pokemon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zji-z-P3xMT7"
      },
      "outputs": [],
      "source": [
        "# Count plot of different types\n",
        "counts = df['type 1'].value_counts().add(df['type 2'].value_counts(), fill_value = 0)\n",
        "counts.plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfpCLmmy-HHK"
      },
      "outputs": [],
      "source": [
        "# Normalized Probabilities Plot\n",
        "(100*counts/counts.sum()).plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXyvPXI2P8Kx"
      },
      "outputs": [],
      "source": [
        "# Spawn duration\n",
        "spawn = df[df['encounter_ms'].notnull()]['encounter_ms'] - df[df['encounter_ms'].notnull()]['spawn_ms']\n",
        "sns.histplot(spawn.astype('timedelta64[s]')/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GtKmB9pUXEr"
      },
      "outputs": [],
      "source": [
        "sns.histplot(data=df,x='encounter_ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PFoi4q_8ChH"
      },
      "outputs": [],
      "source": [
        "# Scatterplot of encounter times of different pokemon\n",
        "sns.scatterplot(data=df,x='encounter_ms',y='num')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjqnKFEcM_1U"
      },
      "outputs": [],
      "source": [
        "# Geospatial analysis of plots\n",
        "df.plot(kind='scatter', x='lng', y='lat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWiuyaWjSb7t"
      },
      "outputs": [],
      "source": [
        "# Selecting only points at San Francisco\n",
        "sanfrancisco_df = df[(df['lng'] <= -121.674) & (df['lat'] >= 37.196)]\n",
        "sanfrancisco_df.plot(kind = 'scatter', x = 'lng', y='lat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUbRSOivNTsY"
      },
      "outputs": [],
      "source": [
        "sanfrancisco_df.plot(kind='hexbin', x='lng', y='lat', gridsize=20, colormap='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc8iNOU4UwgM"
      },
      "outputs": [],
      "source": [
        "# Using Seaborn to generate a hexbin jointplot\n",
        "sns.jointplot(x=sanfrancisco_df['lng'],y=sanfrancisco_df['lat'], kind='hex', joint_kws={'gridsize':20})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19NYXGAgr9-x"
      },
      "source": [
        "## Plot.ly\n",
        "One caveat for both Seaborn & Matplotlib is the lack of interactivity (ability to zoom in to graphs, pan graph windows, and display information about datapoints when hovering over them). Plotly provides a viable, yet relatively high performance alternative. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD3QB_yDr_1r"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BLPWc11sLah"
      },
      "outputs": [],
      "source": [
        "# Taking another look at our processed dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPkAqi3rZN8P"
      },
      "outputs": [],
      "source": [
        "# Plotting a count plot of pokemon types using plotly\n",
        "fig = px.bar(x=counts.index, y=counts, labels={'y':'Counts','x':'Pokemon Types'}, color=counts.index, title='Histogram of Pokemon Types')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40q55TYgdiyy"
      },
      "outputs": [],
      "source": [
        "# Plotly Histogram\n",
        "fig = px.histogram(df,x='encounter_ms')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9tjMmRdstaS"
      },
      "outputs": [],
      "source": [
        "# Interactive scatterplot with plotly\n",
        "fig = px.scatter(df.sample(30000), x=\"encounter_ms\", y=\"num\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w8uPYVLGzxU"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(sanfrancisco_df.sample(30000),x='lng',y='lat',hover_name='name',color='num',hover_data=['spawn_ms'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEQjzZ5r9gfc"
      },
      "source": [
        "## Kepler.gl\n",
        "\n",
        "Plotting geospatial data using Matplotlib is viable using a traditional scatterplot or a hexbin plot, but there offers way more efficient and useful tools specifically engineered to handle such geospatial datasets. \n",
        "\n",
        "Kepler.gl is a powerful open source geospatial analysis tool for large-scale data sets, that offers both visual appeal and a broad range of functionality including interactivity, filters and different map types. \n",
        "\n",
        "For more information, visit their [GitHub](https://github.com/keplergl/kepler.gl)\n",
        "\n",
        "Here, we will be importing our dataset into keplergl, and exploring the various functionality within this tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fijAz1Ud9ieQ"
      },
      "outputs": [],
      "source": [
        "! pip install keplergl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ufvRoZ79rgn"
      },
      "outputs": [],
      "source": [
        "from keplergl import KeplerGl\n",
        "# to view Kepler GL output\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iuh1fUJGY9i"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary data to avoid bloating\n",
        "spawn_map_df = df.drop(columns=['encounter_ms','type 1','type 2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUAlph_gf-bA"
      },
      "outputs": [],
      "source": [
        "spawn_map_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXHCTreX-ufW"
      },
      "outputs": [],
      "source": [
        "# Displaying a map of all spawns\n",
        "spawn_map = KeplerGl(height=400)\n",
        "spawn_map.add_data(data=spawn_map_df.sample(30000), name=\"Spawn Map Data\")\n",
        "spawn_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVvsNcnNpjpw"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary data to avoid bloating\n",
        "unencountered_map_df = df[df['encounter_ms'].isnull()].drop(columns={'encounter_ms'})\n",
        "print(unencountered_map_df.shape)\n",
        "unencountered_map_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4cF3RB-pwZ3"
      },
      "outputs": [],
      "source": [
        "# Challenge 3: Displaying a map of all unencountered pokemon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvKdvAHBAm3L"
      },
      "outputs": [],
      "source": [
        "# Using the kepler.gl webapp\n",
        "unencountered_map_df.to_csv('unencountered_map.csv')\n",
        "spawn_map_df.sample(30000).to_csv('spawn_map.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhRliTeGc6iR"
      },
      "source": [
        "## Insights gained:\n",
        "1. Anomalous data found at **Tokyo** region\n",
        "2. Top 10 most common pokemon: **Pidgey, Zubat, Rattata, Spearow, Weedle, Doduo, Ekans, Paras, Eevee, Magikarp**\n",
        "3. Top 10 least common pokemon: **Omastar, Muk, Gyarados, Vaporeon, Cloyster, Machamp, Vileplume, Dewgong, Victreebel, Alakazam**\n",
        "4. Most common spawn types: **Normal, Flying, Poison**\n",
        "5. Spawn Duration: **15mins**\n",
        "6. Dataset clustered on **26 July 2016**, encounters peak at **18:20**\n",
        "7. **No underlying hotspots** for unencountered pokemon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJZnDuxgetNf"
      },
      "source": [
        "# Machine Learning (HC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8DVgrxuhCsM"
      },
      "source": [
        "## [Netron.app](https://netron.app/)\n",
        "\n",
        "Netron allows you to view your neural network, deep learning and machine learning models.\n",
        "\n",
        "You can use it with most of the commonly used machine learning libraries such as PyTorch, Tensorflow and scikit-learn.\n",
        "\n",
        "For more information, visit their [GitHub](https://github.com/lutzroeder/netron)\n",
        "\n",
        "Here, we will be building a simple [CNN for MNIST](https://www.tensorflow.org/tutorials/images/cnn) with TensorFlow so that we can analyse the neural network, then we will import a more well developed model ([YoloV5](https://github.com/ultralytics/yolov5)) to see the full capabilities of this library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8ldurWilfSK"
      },
      "outputs": [],
      "source": [
        "!pip install -q netron\n",
        "import netron\n",
        "import portpicker\n",
        "from google.colab import output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMlgjf4LhB8q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-iLdlpMerCN"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train = x_train/255\n",
        "\n",
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hTxkJepilu2"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_train[123][:,:,0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC93mTeVjTsT"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THQeN_vTjlVZ"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUuKpulPkvrH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(epsilon=1e-08), loss='categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3xcM4fJk7LW"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijKDOl81nYLu"
      },
      "outputs": [],
      "source": [
        "model.save('mnist_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoZxa8Fcl7Vq"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93phTQlDk8E-"
      },
      "outputs": [],
      "source": [
        "port = portpicker.pick_unused_port()\n",
        "with output.temporary():\n",
        "  netron.start('mnist_model.h5', address=(\"0.0.0.0\", port), browse=False)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='500')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R29TTRfem5ET"
      },
      "outputs": [],
      "source": [
        "!curl --output resnet.h5 -L https://github.com/Hyperparticle/one-pixel-attack-keras/raw/master/networks/models/resnet.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BEiXtOQvZKF"
      },
      "outputs": [],
      "source": [
        "resnet = tf.keras.models.load_model('resnet.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgE5KjghvafT"
      },
      "outputs": [],
      "source": [
        "resnet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ymZgB3FqGRZ"
      },
      "outputs": [],
      "source": [
        "port = portpicker.pick_unused_port()\n",
        "with output.temporary():\n",
        "  netron.start('resnet.h5', address=(\"0.0.0.0\", port), browse=False)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='500')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAWLO4SMEOwv"
      },
      "source": [
        "## [ANN Visualizer](https://github.com/RedaOps/ann-visualizer)\n",
        "\n",
        "ANN Visualizer is more useful if you're using a normal python script instead of running in Google Colab.\n",
        "\n",
        "It's easy to use with basically 0 configuration needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjX7zVRaAXwO"
      },
      "outputs": [],
      "source": [
        "!pip install ann_visualizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia3Q6v0GAXtk"
      },
      "outputs": [],
      "source": [
        "from ann_visualizer.visualize import ann_viz\n",
        "\n",
        "ann_viz(model, title=\"CNN\", view=True, filename=\"visualized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8sk7-4BHQ2S"
      },
      "source": [
        "## Manual Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bsd1A8b3NcI7"
      },
      "outputs": [],
      "source": [
        "layer_names = [layer.name for layer in resnet.layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3CzqtxLHSlc"
      },
      "outputs": [],
      "source": [
        "layer_outputs = [layer.output for layer in resnet.layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPre7vWIHSji"
      },
      "outputs": [],
      "source": [
        "feature_map_model = tf.keras.models.Model(resnet.input, layer_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u8DEJSyHSg-"
      },
      "outputs": [],
      "source": [
        "!wget https://live.staticflickr.com/65535/49852239266_6d2486b7e3_k_d.jpg -O sample.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R8e0bddR0zq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "image = load_img('./sample.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UjxZhcbR1UO"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUr4AKGYHSek"
      },
      "outputs": [],
      "source": [
        "image = load_img('./sample.jpg', target_size=(32,32))\n",
        "plt.imshow(image)\n",
        "im = img_to_array(image)\n",
        "im = im.reshape((1,) + im.shape)\n",
        "im /= 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmmoEtEtHScD"
      },
      "outputs": [],
      "source": [
        "feature_maps = feature_map_model.predict(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFNNnjN4P4WW"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for layer_name, feature_map in zip(layer_names, feature_maps):\n",
        "  if count >= 10:\n",
        "    break\n",
        "  if len(feature_map.shape) == 4:\n",
        "\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      # Tile each filter into a horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x# Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTIjaqakwDac"
      },
      "source": [
        "## [Tensorboard](https://www.tensorflow.org/tensorboard)\n",
        "\n",
        "Tensorboard is much more well known compared to the other libraries we've introduced. Nevertheless, it is still an extremely useful resource for visualising machine learning models that we've decided to include it here.\n",
        "\n",
        "Mastering the use of Tensorboard will make your Machine Learning journey much easier, especially for people who find it hard to visualise models in their mind."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk97GinMtmLc"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdSMl9IzxZWK"
      },
      "outputs": [],
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUlVDtQ6xdgh"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train = x_train/255\n",
        "\n",
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "\n",
        "batch_size = 256 # Changed this to make it go faster\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(32, (5,5), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(epsilon=1e-08), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard_callback] # New addition\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEfAFiOlVZrN"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agipiCUuu_dg"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW07o-LB5WP9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeng3T8v0YAF"
      },
      "source": [
        "### Tensorboard with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je7ppLajvDu4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Writer will output to ./runs/ directory by default\n",
        "writer = SummaryWriter()\n",
        "\n",
        "x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
        "y = -5 * x + 0.1 * torch.randn(x.size())\n",
        "\n",
        "model = torch.nn.Linear(1, 1)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
        "\n",
        "def train_model(iter):\n",
        "    for epoch in range(iter):\n",
        "        y1 = model(x)\n",
        "        loss = criterion(y1, y)\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "train_model(10)\n",
        "writer.flush()\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8cjWDRLypPL"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhSDVesu0EeP"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFKwhWY_58u4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}